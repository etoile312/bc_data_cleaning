import json
import requests
import time
import os
import re
from pathlib import Path
from sentence_transformers import SentenceTransformer
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
from bert_score import score
import numpy as np

# æ¸…ç†ä»£ç†ç¯å¢ƒå˜é‡ï¼Œé¿å…ä»£ç†è¿æ¥é—®é¢˜
for var in ("HTTP_PROXY", "HTTPS_PROXY", "ALL_PROXY", "http_proxy", "https_proxy", "all_proxy"):
    os.environ.pop(var, None)

# ChatFlowï¼ˆAIé—®ç­”ï¼‰é…ç½®
CHATFLOW_API_URL = 'https://api.dify.ai/v1/chat-messages'
CHATFLOW_API_KEY = 'Bearer app-W0Vf8phyDHlPRyDkat7HczOK'
CHATFLOW_HEADERS = {
    'Authorization': CHATFLOW_API_KEY,
    'Content-Type': 'application/json',
}

# åˆå§‹åŒ–æ¨¡å‹
print("ğŸ”§ æ­£åœ¨åŠ è½½è¯„ä¼°æ¨¡å‹...")
try:
    # 1. æ–‡æœ¬åµŒå…¥æ¨¡å‹ (ç”¨äºContext Relevance)
    embedding_model = SentenceTransformer('shibing624/text2vec-base-chinese')
    print("âœ… æ–‡æœ¬åµŒå…¥æ¨¡å‹åŠ è½½å®Œæˆ")
    
    # 2. NLIæ¨¡å‹ (ç”¨äºAnswer Faithfulnesså’ŒAnswer Relevance)
    nli_model_name = 'MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli'
    nli_tokenizer = AutoTokenizer.from_pretrained(nli_model_name)
    nli_model = AutoModelForSequenceClassification.from_pretrained(nli_model_name)
    nli_model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    print("âœ… NLIæ¨¡å‹åŠ è½½å®Œæˆ")
    
    # 3. BERTScoreæ¨¡å‹ (ç”¨äºAnswer Correctness)
    print("âœ… BERTScoreæ¨¡å‹å‡†å¤‡å°±ç»ª")
    
except Exception as e:
    print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    exit(1)

def call_chatflow_api(question):
    """è°ƒç”¨ChatFlow API"""
    data = {
        "inputs": {},
        "query": question,
        "response_mode": "blocking",  # ä½¿ç”¨blockingæ¨¡å¼
        "user": "test_user_001"
    }
    
    try:
        print(f"  è°ƒç”¨APIå¤„ç†é—®é¢˜: {question[:50]}...")
        start_time = time.time()
        response = requests.post(CHATFLOW_API_URL, headers=CHATFLOW_HEADERS, data=json.dumps(data), timeout=120)
        end_time = time.time()
        
        print(f"  â±ï¸ APIè°ƒç”¨è€—æ—¶: {end_time - start_time:.2f}ç§’")
        print(f"  ğŸ“Š çŠ¶æ€ç : {response.status_code}")
        
        if response.status_code == 200:
            print("  âœ… APIè°ƒç”¨æˆåŠŸï¼")
            return response.json()
        else:
            print(f"  âš ï¸ APIè°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            print(f"  ğŸ“„ é”™è¯¯å“åº”: {response.text}")
            return None
            
    except requests.exceptions.RequestException as e:
        print(f"  âŒ APIè°ƒç”¨å¼‚å¸¸: {e}")
        return None

def extract_context_and_answer(response_data):
    """ä»APIå“åº”ä¸­æå–retrieved_contextå’Œanswer"""
    try:
        # è·å–answerå­—æ®µ
        answer_text = response_data.get('answer', '')
        print(f"  ğŸ“„ åŸå§‹answeré•¿åº¦: {len(answer_text)}")
        
        # å°è¯•è§£æJSONæ ¼å¼çš„answer
        try:
            # æŸ¥æ‰¾JSONå¼€å§‹å’Œç»“æŸçš„ä½ç½®
            start_idx = answer_text.find('{')
            end_idx = answer_text.rfind('}') + 1
            
            if start_idx != -1 and end_idx > start_idx:
                json_str = answer_text[start_idx:end_idx]
                parsed = json.loads(json_str)
                
                retrieved_context = parsed.get('retrieved_context', '')
                ai_answer = parsed.get('answer', '')
                
                print(f"  âœ… æˆåŠŸæå–retrieved_contextå’Œanswer")
                print(f"  ğŸ“ retrieved_contexté•¿åº¦: {len(retrieved_context)}")
                print(f"  ğŸ“ ai_answeré•¿åº¦: {len(ai_answer)}")
                
                return retrieved_context, ai_answer
            else:
                print(f"  âš ï¸ æœªæ‰¾åˆ°JSONæ ¼å¼ï¼Œä½¿ç”¨åŸå§‹answer")
                return '', answer_text
                
        except json.JSONDecodeError as e:
            print(f"  âš ï¸ JSONè§£æå¤±è´¥: {e}")
            print(f"  ğŸ“„ ä½¿ç”¨åŸå§‹answerä½œä¸ºai_answer")
            return '', answer_text
            
    except Exception as e:
        print(f"  âŒ æå–æ•°æ®å¤±è´¥: {e}")
        return '', ''

def calculate_context_relevance(question, retrieved_context):
    """è®¡ç®—ä¸Šä¸‹æ–‡ç›¸å…³æ€§ (Context Relevance)"""
    try:
        # ä½¿ç”¨Sentence-Transformersè®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        embeddings = embedding_model.encode([question, retrieved_context])
        similarity = np.dot(embeddings[0], embeddings[1]) / (np.linalg.norm(embeddings[0]) * np.linalg.norm(embeddings[1]))
        return float(similarity)
    except Exception as e:
        print(f"  âŒ Context Relevanceè®¡ç®—å¤±è´¥: {e}")
        return 0.0

def calculate_answer_faithfulness(retrieved_context, ai_answer):
    """ç”¨embeddingä½™å¼¦ç›¸ä¼¼åº¦è¿‘ä¼¼ç­”æ¡ˆå¿ å®åº¦ (Answer Faithfulness)"""
    try:
        embeddings = embedding_model.encode([retrieved_context, ai_answer])
        similarity = np.dot(embeddings[0], embeddings[1]) / (np.linalg.norm(embeddings[0]) * np.linalg.norm(embeddings[1]))
        return float(similarity)
    except Exception as e:
        print(f"  âŒ Answer Faithfulnessè®¡ç®—å¤±è´¥: {e}")
        return 0.0

def calculate_answer_relevance(question, ai_answer):
    """ç”¨embeddingä½™å¼¦ç›¸ä¼¼åº¦è¿‘ä¼¼ç­”æ¡ˆç›¸å…³æ€§ (Answer Relevance)"""
    try:
        embeddings = embedding_model.encode([question, ai_answer])
        similarity = np.dot(embeddings[0], embeddings[1]) / (np.linalg.norm(embeddings[0]) * np.linalg.norm(embeddings[1]))
        return float(similarity)
    except Exception as e:
        print(f"  âŒ Answer Relevanceè®¡ç®—å¤±è´¥: {e}")
        return 0.0

def calculate_answer_correctness(ai_answer, ref_answer):
    """è®¡ç®—ç­”æ¡ˆæ­£ç¡®æ€§ (Answer Correctness)"""
    try:
        # ä½¿ç”¨BERTScoreè®¡ç®—è¯­ä¹‰åŒ¹é…åº¦
        P, R, F1 = score([ai_answer], [ref_answer], lang='zh', verbose=False)
        return float(F1[0])
    except Exception as e:
        print(f"  âŒ Answer Correctnessè®¡ç®—å¤±è´¥: {e}")
        return 0.0

def extract_keywords(text):
    """æå–å…³é”®è¯/å®ä½“"""
    # ç®€å•çš„å…³é”®è¯æå–ï¼šåŒ»ç–—ç›¸å…³è¯æ±‡
    medical_keywords = [
        'ä¹³å¤´', 'æº¢æ¶²', 'ä¹³æˆ¿', 'ä¹³è…º', 'æœˆç»', 'æ£€æŸ¥', 'æ²»ç–—', 'åŒ»é™¢', 'åŒ»ç”Ÿ',
        'ç—‡çŠ¶', 'ç–¼ç—›', 'èƒ€ç—›', 'ç™½è‰²', 'æ¶²ä½“', 'æ¿€ç´ ', 'é›Œæ¿€ç´ ', 'å‚¬ä¹³ç´ ',
        'å¢ç”Ÿ', 'å¯¼ç®¡', 'ç»†èƒ', 'ç—…ç†', 'è¶…å£°', 'é’¼é¶', 'ä¹³é€'
    ]
    
    found_keywords = []
    for keyword in medical_keywords:
        if keyword in text:
            found_keywords.append(keyword)
    
    return found_keywords

def calculate_context_recall(ref_answer, retrieved_context):
    """è®¡ç®—ä¸Šä¸‹æ–‡å¬å›ç‡ (Context Recall)"""
    try:
        # æå–ref_answerä¸­çš„å…³é”®è¯
        ref_keywords = extract_keywords(ref_answer)
        
        if not ref_keywords:
            return 0.0
        
        # ç»Ÿè®¡è¿™äº›å…³é”®è¯åœ¨retrieved_contextä¸­å‡ºç°çš„æ¯”ä¾‹
        found_count = 0
        for keyword in ref_keywords:
            if keyword in retrieved_context:
                found_count += 1
        
        recall = found_count / len(ref_keywords)
        return recall
    except Exception as e:
        print(f"  âŒ Context Recallè®¡ç®—å¤±è´¥: {e}")
        return 0.0

def calculate_rag_score_mean(scores):
    """è®¡ç®—RAGè¯„åˆ†å‡å€¼"""
    valid_scores = [score for score in scores.values() if score is not None]
    if valid_scores:
        return sum(valid_scores) / len(valid_scores)
    return 0.0

def process_first_qa_file():
    """å¤„ç†ç¬¬ä¸€ä¸ªQAæ–‡ä»¶å¹¶è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path('chatflow_results')
    output_dir.mkdir(exist_ok=True)
    
    # è¯»å–ç¬¬ä¸€ä¸ªqaæ–‡ä»¶
    qa_file = Path('breast_cancer_cmed_files/qa01_cmed.json')
    
    if not qa_file.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {qa_file}")
        return
    
    print(f"ğŸ“ å¤„ç†æ–‡ä»¶: {qa_file.name}")
    
    # è¯»å–QAæ–‡ä»¶
    with open(qa_file, 'r', encoding='utf-8') as f:
        qa_data = json.load(f)
    
    question = qa_data['question']
    ref_answer = qa_data['answers'][0] if qa_data['answers'] else ''
    
    print(f"ğŸ“ é—®é¢˜: {question[:100]}...")
    print(f"ğŸ“ å‚è€ƒç­”æ¡ˆ: {ref_answer[:100]}...")
    
    # è°ƒç”¨ChatFlow API
    response = call_chatflow_api(question)
    
    if response:
        retrieved_context, ai_answer = extract_context_and_answer(response)
        
        print("\nğŸ“Š å¼€å§‹è®¡ç®—è¯„ä¼°æŒ‡æ ‡...")
        
        # è®¡ç®—å„é¡¹è¯„ä¼°æŒ‡æ ‡
        context_relevance = calculate_context_relevance(question, retrieved_context)
        faithfulness = calculate_answer_faithfulness(retrieved_context, ai_answer)
        answer_relevance = calculate_answer_relevance(question, ai_answer)
        answer_correctness = calculate_answer_correctness(ai_answer, ref_answer)
        context_recall = calculate_context_recall(ref_answer, retrieved_context)
        
        # è®¡ç®—RAGè¯„åˆ†å‡å€¼
        scores = {
            'context_relevance': context_relevance,
            'faithfulness': faithfulness,
            'answer_relevance': answer_relevance,
            'answer_correctness': answer_correctness,
            'context_recall': context_recall
        }
        rag_score_mean = calculate_rag_score_mean(scores)
        
        # åˆ›å»ºç»“æœæ•°æ®
        result_data = {
            "question": question,
            "retrieved_context": retrieved_context,
            "ai_answer": ai_answer,
            "ref_answer": ref_answer,
            "context_relevance": context_relevance,
            "faithfulness": faithfulness,
            "answer_relevance": answer_relevance,
            "answer_correctness": answer_correctness,
            "context_recall": context_recall,
            "rag_score_mean": rag_score_mean
        }
        
        # ä¿å­˜ç»“æœæ–‡ä»¶
        result_filename = "result01_cmed.json"
        result_filepath = output_dir / result_filename
        
        with open(result_filepath, 'w', encoding='utf-8') as f:
            json.dump(result_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… å·²ä¿å­˜ç»“æœåˆ°: {result_filename}")
        print(f"ğŸ“Š è¯„ä¼°æŒ‡æ ‡ç»“æœ:")
        print(f"   - Context Relevance: {context_relevance:.4f}")
        print(f"   - Faithfulness: {faithfulness:.4f}")
        print(f"   - Answer Relevance: {answer_relevance:.4f}")
        print(f"   - Answer Correctness: {answer_correctness:.4f}")
        print(f"   - Context Recall: {context_recall:.4f}")
        print(f"   - RAG Score Mean: {rag_score_mean:.4f}")
        
    else:
        print(f"âŒ å¤„ç†å¤±è´¥: {qa_file.name}")

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹å¤„ç†ç¬¬ä¸€ä¸ªQAæ–‡ä»¶å¹¶è®¡ç®—è¯„ä¼°æŒ‡æ ‡...")
    process_first_qa_file()
    print("ğŸ å¤„ç†å®Œæˆï¼") 